{"cells":[{"cell_type":"markdown","source":["# Null Handling in PySpark"],"metadata":{},"id":"a0a703c0-1909-45ab-b6f9-35be49bc99c8"},{"cell_type":"code","source":["# Import necessary libraries\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, isnull, coalesce, lit\n","\n","# Create a Spark session\n","spark = SparkSession.builder.appName(\"NullHandling\").getOrCreate()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"c1e48d9e-8391-4063-a5f4-93cc537fa3ac","normalized_state":"finished","queued_time":"2025-02-23T16:37:55.2060275Z","session_start_time":"2025-02-23T16:37:55.2075552Z","execution_start_time":"2025-02-23T16:38:11.08041Z","execution_finish_time":"2025-02-23T16:38:13.8034081Z","parent_msg_id":"c7c6560d-e3dd-4ee0-b4b2-90c85d68fbe6"},"text/plain":"StatementMeta(, c1e48d9e-8391-4063-a5f4-93cc537fa3ac, 3, Finished, Available, Finished)"},"metadata":{}}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c99d3cde-f734-493e-b7ec-44b72667fc40"},{"cell_type":"markdown","source":["## Sample Sales Data with Null Values"],"metadata":{},"id":"4746a9c9-cf58-4c8c-b57d-e8423d6da672"},{"cell_type":"code","source":["# Sample data: sales data with nulls\n","data = [\n","    (\"John\", \"North\", 100, None),\n","    (\"Doe\", \"East\", None, 50),\n","    (None, \"West\", 150, 30),\n","    (\"Alice\", None, 200, 40),\n","    (\"Bob\", \"South\", None, None),\n","    (None, None, None, None)\n","]\n","columns = [\"Name\", \"Region\", \"UnitsSold\", \"Revenue\"]\n","\n","# Create DataFrame\n","df = spark.createDataFrame(data, columns)\n","df.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"c1e48d9e-8391-4063-a5f4-93cc537fa3ac","normalized_state":"finished","queued_time":"2025-02-23T16:37:55.2071492Z","session_start_time":null,"execution_start_time":"2025-02-23T16:38:14.0228006Z","execution_finish_time":"2025-02-23T16:38:17.6810663Z","parent_msg_id":"f8cb91ae-e3c5-447b-969a-005c694a2d37"},"text/plain":"StatementMeta(, c1e48d9e-8391-4063-a5f4-93cc537fa3ac, 4, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+-----+------+---------+-------+\n| Name|Region|UnitsSold|Revenue|\n+-----+------+---------+-------+\n| John| North|      100|   NULL|\n|  Doe|  East|     NULL|     50|\n| NULL|  West|      150|     30|\n|Alice|  NULL|      200|     40|\n|  Bob| South|     NULL|   NULL|\n| NULL|  NULL|     NULL|   NULL|\n+-----+------+---------+-------+\n\n"]}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"33c9e419-6104-44b2-87de-c49eee17aa64"},{"cell_type":"markdown","source":["## 1. Detecting Null Values"],"metadata":{},"id":"6bd974b6-9de4-4e7d-91f6-274b07a25950"},{"cell_type":"code","source":["# Identify null values in specific columns\n","df.select(col(\"Name\"), col(\"Region\"), col(\"UnitsSold\"), col(\"Revenue\"),\n","          col(\"Name\").isNull().alias(\"Name_is_null\"),\n","          col(\"Region\").isNull().alias(\"Region_is_null\"),\n","          col(\"UnitsSold\").isNull().alias(\"UnitsSold_is_null\"),\n","          col(\"Revenue\").isNull().alias(\"Revenue_is_null\")\n","         ).show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"c1e48d9e-8391-4063-a5f4-93cc537fa3ac","normalized_state":"finished","queued_time":"2025-02-23T16:37:55.2081856Z","session_start_time":null,"execution_start_time":"2025-02-23T16:38:17.8743987Z","execution_finish_time":"2025-02-23T16:38:18.7690774Z","parent_msg_id":"dd4fa2cc-daf8-46e2-8eba-a0ffaaba1361"},"text/plain":"StatementMeta(, c1e48d9e-8391-4063-a5f4-93cc537fa3ac, 5, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+-----+------+---------+-------+------------+--------------+-----------------+---------------+\n| Name|Region|UnitsSold|Revenue|Name_is_null|Region_is_null|UnitsSold_is_null|Revenue_is_null|\n+-----+------+---------+-------+------------+--------------+-----------------+---------------+\n| John| North|      100|   NULL|       false|         false|            false|           true|\n|  Doe|  East|     NULL|     50|       false|         false|             true|          false|\n| NULL|  West|      150|     30|        true|         false|            false|          false|\n|Alice|  NULL|      200|     40|       false|          true|            false|          false|\n|  Bob| South|     NULL|   NULL|       false|         false|             true|           true|\n| NULL|  NULL|     NULL|   NULL|        true|          true|             true|           true|\n+-----+------+---------+-------+------------+--------------+-----------------+---------------+\n\n"]}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"94a3bc2d-2bf6-496f-843c-8ef220d4fd56"},{"cell_type":"markdown","source":["## 2. Dropping Rows with Null Values"],"metadata":{},"id":"002a6078-092e-4786-ace9-3f4f6331b444"},{"cell_type":"code","source":["# Drop rows containing null values in any column\n","df_drop_any = df.dropna()\n","df_drop_any.show()\n","\n","# Drop rows only if all columns contain null values\n","df_drop_all = df.dropna(how='all')\n","df_drop_all.show()\n","\n","# Drop rows where specific columns contain null values\n","df_drop_subset = df.dropna(subset=[\"Name\", \"UnitsSold\"])\n","df_drop_subset.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"state":"finished","livy_statement_state":"available","session_id":"c1e48d9e-8391-4063-a5f4-93cc537fa3ac","normalized_state":"finished","queued_time":"2025-02-23T16:37:55.208969Z","session_start_time":null,"execution_start_time":"2025-02-23T16:38:18.9846696Z","execution_finish_time":"2025-02-23T16:38:21.5465954Z","parent_msg_id":"0b29e257-23f4-4d93-bfa1-d2b54c981f29"},"text/plain":"StatementMeta(, c1e48d9e-8391-4063-a5f4-93cc537fa3ac, 6, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+----+------+---------+-------+\n|Name|Region|UnitsSold|Revenue|\n+----+------+---------+-------+\n+----+------+---------+-------+\n\n+-----+------+---------+-------+\n| Name|Region|UnitsSold|Revenue|\n+-----+------+---------+-------+\n| John| North|      100|   NULL|\n|  Doe|  East|     NULL|     50|\n| NULL|  West|      150|     30|\n|Alice|  NULL|      200|     40|\n|  Bob| South|     NULL|   NULL|\n+-----+------+---------+-------+\n\n+-----+------+---------+-------+\n| Name|Region|UnitsSold|Revenue|\n+-----+------+---------+-------+\n| John| North|      100|   NULL|\n|Alice|  NULL|      200|     40|\n+-----+------+---------+-------+\n\n"]}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0a11eb73-e5f1-4b7f-a2e1-514ef0732632"},{"cell_type":"markdown","source":["## 3. Filling Null Values"],"metadata":{},"id":"8245196e-6b84-42ba-a29f-3858eb971eeb"},{"cell_type":"code","source":["# Fill null values in specific columns\n","df_fill = df.fillna({\"Region\": \"Unknown\", \"UnitsSold\": 0, \"Revenue\": 0})\n","df_fill.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":7,"statement_ids":[7],"state":"finished","livy_statement_state":"available","session_id":"c1e48d9e-8391-4063-a5f4-93cc537fa3ac","normalized_state":"finished","queued_time":"2025-02-23T16:37:55.2097211Z","session_start_time":null,"execution_start_time":"2025-02-23T16:38:21.7511312Z","execution_finish_time":"2025-02-23T16:38:22.618222Z","parent_msg_id":"75c0bc4c-29c3-4ffe-82a9-36ce5de2ba2c"},"text/plain":"StatementMeta(, c1e48d9e-8391-4063-a5f4-93cc537fa3ac, 7, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+-----+-------+---------+-------+\n| Name| Region|UnitsSold|Revenue|\n+-----+-------+---------+-------+\n| John|  North|      100|      0|\n|  Doe|   East|        0|     50|\n| NULL|   West|      150|     30|\n|Alice|Unknown|      200|     40|\n|  Bob|  South|        0|      0|\n| NULL|Unknown|        0|      0|\n+-----+-------+---------+-------+\n\n"]}],"execution_count":5,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"64def495-b5fd-44a7-9576-03474705d7ab"},{"cell_type":"markdown","source":["## 4. Using Coalesce to Handle Nulls in Aggregations"],"metadata":{},"id":"3916b2ab-b4c7-42a4-8a3e-894157e0e722"},{"cell_type":"code","source":["# Using coalesce to replace nulls with fallback values\n","df_coalesce = df.select(\n","    col(\"Name\"),\n","    col(\"Region\"),\n","    coalesce(col(\"UnitsSold\"), lit(0)).alias(\"UnitsSold_Filled\"),\n","    coalesce(col(\"Revenue\"), lit(0)).alias(\"Revenue_Filled\")\n",")\n","df_coalesce.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":8,"statement_ids":[8],"state":"finished","livy_statement_state":"available","session_id":"c1e48d9e-8391-4063-a5f4-93cc537fa3ac","normalized_state":"finished","queued_time":"2025-02-23T16:37:55.2116517Z","session_start_time":null,"execution_start_time":"2025-02-23T16:38:22.8590156Z","execution_finish_time":"2025-02-23T16:38:23.7465648Z","parent_msg_id":"78dfab6a-2685-43ed-bfa2-c2a33d4dab39"},"text/plain":"StatementMeta(, c1e48d9e-8391-4063-a5f4-93cc537fa3ac, 8, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+-----+------+----------------+--------------+\n| Name|Region|UnitsSold_Filled|Revenue_Filled|\n+-----+------+----------------+--------------+\n| John| North|             100|             0|\n|  Doe|  East|               0|            50|\n| NULL|  West|             150|            30|\n|Alice|  NULL|             200|            40|\n|  Bob| South|               0|             0|\n| NULL|  NULL|               0|             0|\n+-----+------+----------------+--------------+\n\n"]}],"execution_count":6,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c4fb0026-4792-45d3-adb9-a594c007d925"},{"cell_type":"markdown","source":["### Summary of Null Handling in PySpark\n","1. **Detecting Nulls**: Use `isNull()` to identify missing values.\n","2. **Dropping Nulls**: Use `dropna()` to remove rows containing nulls.\n","3. **Filling Nulls**: Use `fillna()` to replace nulls with default values.\n","4. **Coalesce Function**: Use `coalesce()` to provide fallback values in case of nulls.\n","5. **Handling Aggregations**: Use `coalesce()` in aggregation functions to avoid null impact."],"metadata":{},"id":"8ae8a94e-e5fc-4795-87a1-871f6f8bbe1d"}],"metadata":{"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"kernel_info":{"name":"synapse_pyspark"},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}}},"nbformat":4,"nbformat_minor":5}
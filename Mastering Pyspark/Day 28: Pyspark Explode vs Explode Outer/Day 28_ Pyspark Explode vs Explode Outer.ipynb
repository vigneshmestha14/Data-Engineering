{"cells":[{"cell_type":"markdown","source":["# Explode vs Explode Outer in PySpark\n","In PySpark, `explode` and `explode_outer` are functions used to work with nested data structures like arrays or maps by **flattening** each element into separate rows. The key difference between them lies in how they handle null or empty arrays."],"metadata":{},"id":"4e896f0b"},{"cell_type":"markdown","source":["## 1. explode()\n","**`explode()`** takes an array or map column and creates a new row for each element.\n","**If the array is empty or null, it drops the row entirely.**"],"metadata":{},"id":"a5840f55"},{"cell_type":"markdown","source":["### Key Characteristics:\n","- Converts each element in an array (or key-value pair in a map) into its own row.\n","- **Drops** rows where the array is empty (`[]`) or null (`None`)."],"metadata":{},"id":"17896302"},{"cell_type":"markdown","source":["### Syntax:\n","```python\n","from pyspark.sql.functions import explode\n","df.select(explode(df['column_with_array'])).show()\n","```"],"metadata":{},"id":"7ade2d0b"},{"cell_type":"markdown","source":["### Example of `explode()`"],"metadata":{},"id":"310a6817"},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import explode\n","\n","# Initialize Spark session\n","spark = SparkSession.builder.appName('ExplodeExample').getOrCreate()\n","\n","# Sample DataFrame with arrays\n","data = [\n","    ('Alice', ['Math', 'Science']),\n","    ('Bob', ['History']),\n","    ('Cathy', []),  # Empty array\n","    ('David', None)  # Null array\n","]\n","\n","df = spark.createDataFrame(data, ['Name', 'Subjects'])\n","df.show()\n","\n","# Use explode to flatten the array\n","exploded_df = df.select('Name', explode('Subjects').alias('Subject'))\n","exploded_df.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"0d0141b8-480f-4fbf-a48d-5fcb5cfb5f89","normalized_state":"finished","queued_time":"2025-03-10T15:38:03.4161291Z","session_start_time":"2025-03-10T15:38:03.4174972Z","execution_start_time":"2025-03-10T15:38:12.8154793Z","execution_finish_time":"2025-03-10T15:38:16.4601374Z","parent_msg_id":"d68e6377-6b6b-4ef1-b0af-2f703604edee"},"text/plain":"StatementMeta(, 0d0141b8-480f-4fbf-a48d-5fcb5cfb5f89, 3, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+-----+---------------+\n| Name|       Subjects|\n+-----+---------------+\n|Alice|[Math, Science]|\n|  Bob|      [History]|\n|Cathy|             []|\n|David|           NULL|\n+-----+---------------+\n\n+-----+-------+\n| Name|Subject|\n+-----+-------+\n|Alice|   Math|\n|Alice|Science|\n|  Bob|History|\n+-----+-------+\n\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b6e4c172"},{"cell_type":"markdown","source":["### Explanation:\n","- `explode()` expands the `Subjects` array into individual rows.\n","- **Rows with empty (`[]`) or null (`None`) arrays are removed**, so Cathy and David do not appear in the output."],"metadata":{},"id":"7d10e5ce"},{"cell_type":"markdown","source":["---\n","## 2. explode_outer()\n","**`explode_outer()`** works similarly to `explode()`, but it **keeps rows** with null or empty arrays, filling them with `null` values in the resulting column."],"metadata":{},"id":"2b0face2"},{"cell_type":"markdown","source":["### Key Characteristics:\n","- Converts each element in an array or each entry in a map into its own row.\n","- **Retains** rows where the array is empty (`[]`) or null (`None`), filling them with `null`. "],"metadata":{},"id":"c3697fae"},{"cell_type":"markdown","source":["### Syntax:\n","```python\n","from pyspark.sql.functions import explode_outer\n","df.select(explode_outer(df['column_with_array'])).show()\n","```"],"metadata":{},"id":"1d15e3f3"},{"cell_type":"markdown","source":["### Example of `explode_outer()`"],"metadata":{},"id":"9e685801"},{"cell_type":"code","source":["from pyspark.sql.functions import explode_outer\n","\n","# Use explode_outer to retain null and empty arrays\n","exploded_outer_df = df.select('Name', explode_outer('Subjects').alias('Subject'))\n","exploded_outer_df.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"0d0141b8-480f-4fbf-a48d-5fcb5cfb5f89","normalized_state":"finished","queued_time":"2025-03-10T15:38:03.4415386Z","session_start_time":null,"execution_start_time":"2025-03-10T15:38:16.462956Z","execution_finish_time":"2025-03-10T15:38:17.9688029Z","parent_msg_id":"769842f2-8507-4dfb-be8f-4fba9281ccfe"},"text/plain":"StatementMeta(, 0d0141b8-480f-4fbf-a48d-5fcb5cfb5f89, 4, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+-----+-------+\n| Name|Subject|\n+-----+-------+\n|Alice|   Math|\n|Alice|Science|\n|  Bob|History|\n|Cathy|   NULL|\n|David|   NULL|\n+-----+-------+\n\n"]}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0d02b484"},{"cell_type":"markdown","source":["### Explanation:\n","- `explode_outer()` expands the `Subjects` array into individual rows.\n","- **Unlike `explode()`, rows with empty (`[]`) or null (`None`) arrays are kept** with `null` values in the `Subject` column."],"metadata":{},"id":"3e69c1b3"},{"cell_type":"markdown","source":["---\n","## Summary Table of Differences\n","\n","| Function         | Description | Null/Empty Arrays Behavior |\n","|-----------------|-------------|-----------------------------|\n","| `explode()`     | Expands each element of an array or map into individual rows | Drops rows with null or empty arrays |\n","| `explode_outer()` | Similar to `explode()`, but retains rows with null or empty arrays | Keeps rows with null or empty arrays, filling with `null` |\n","\n","These functions are useful when working with complex nested data structures, especially when dealing with JSON or other hierarchical data."],"metadata":{},"id":"ff0c1a30"}],"metadata":{"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"kernel_info":{"name":"synapse_pyspark"},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}}},"nbformat":4,"nbformat_minor":5}
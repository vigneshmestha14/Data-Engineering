{"cells":[{"cell_type":"markdown","source":["# **Broadcast Joins in PySpark**\n","###### Broadcast joins (also known as Map-side joins) are a type of optimization technique used when joining a large dataset with a small dataset. The smaller dataset is broadcast to all executor nodes, making the join operation more efficient.\n","\n","##### **When to Use Broadcast Joins:**\n","###### 1. One DataFrame is much smaller than the other\n","###### 2. The smaller DataFrame can fit in memory\n","###### 3. You want to avoid shuffle operations\n","\n","###### Here's an example of how to implement broadcast joins:"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"b5be9e63-e4d7-4e6c-83a3-c019fe2c0488"},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import broadcast\n","\n","# Initialize Spark Session\n","spark = SparkSession.builder.appName(\"Broadcast Join Example\").getOrCreate()\n","\n","# Create sample DataFrames\n","# Large DataFrame\n","large_df = spark.createDataFrame([\n","    (1, \"Product A\"),\n","    (2, \"Product B\"),\n","    (3, \"Product C\"),\n","    (4, \"Product D\")\n","], [\"product_id\", \"product_name\"])\n","\n","# Small DataFrame (good candidate for broadcasting)\n","small_df = spark.createDataFrame([\n","    (1, \"Category 1\"),\n","    (2, \"Category 2\")\n","], [\"product_id\", \"category\"])\n","\n","# Method 1: Using broadcast hint\n","broadcast_join_df = large_df.join(broadcast(small_df), \"product_id\")\n","broadcast_join_df.explain()  # Shows the execution plan with broadcast\n","broadcast_join_df.show()\n","\n","# Method 2: Using configuration\n","# Set broadcast threshold (default is 10MB)\n","spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", 10485760)  # 10MB in bytes\n","\n","# Join will automatically use broadcast if small_df is below threshold\n","auto_broadcast_join_df = large_df.join(small_df, \"product_id\")\n","auto_broadcast_join_df.explain()\n","auto_broadcast_join_df.show()\n","\n","# Disable broadcasting if needed\n","spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":12,"statement_ids":[12],"state":"finished","livy_statement_state":"available","session_id":"fee2b172-d722-4d24-b54c-74a2e3116f71","normalized_state":"finished","queued_time":"2025-02-27T12:59:22.736218Z","session_start_time":null,"execution_start_time":"2025-02-27T12:59:22.9504179Z","execution_finish_time":"2025-02-27T12:59:24.5922839Z","parent_msg_id":"2a4bde78-ccd4-4b91-bae4-9fae3fdc594d"},"text/plain":"StatementMeta(, fee2b172-d722-4d24-b54c-74a2e3116f71, 12, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["== Physical Plan ==\nAdaptiveSparkPlan isFinalPlan=false\n+- Project [product_id#816L, product_name#817, category#821]\n   +- BroadcastHashJoin [product_id#816L], [product_id#820L], Inner, BuildRight, false\n      :- Filter isnotnull(product_id#816L)\n      :  +- Scan ExistingRDD[product_id#816L,product_name#817]\n      +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, bigint, false]),false), [plan_id=1109]\n         +- Filter isnotnull(product_id#820L)\n            +- Scan ExistingRDD[product_id#820L,category#821]\n\n\n+----------+------------+----------+\n|product_id|product_name|  category|\n+----------+------------+----------+\n|         1|   Product A|Category 1|\n|         2|   Product B|Category 2|\n+----------+------------+----------+\n\n== Physical Plan ==\nAdaptiveSparkPlan isFinalPlan=false\n+- Project [product_id#816L, product_name#817, category#821]\n   +- SortMergeJoin [product_id#816L], [product_id#820L], Inner\n      :- Sort [product_id#816L ASC NULLS FIRST], false, 0\n      :  +- Exchange hashpartitioning(product_id#816L, 200), ENSURE_REQUIREMENTS, [plan_id=1206]\n      :     +- Filter isnotnull(product_id#816L)\n      :        +- Scan ExistingRDD[product_id#816L,product_name#817]\n      +- Sort [product_id#820L ASC NULLS FIRST], false, 0\n         +- Exchange hashpartitioning(product_id#820L, 200), ENSURE_REQUIREMENTS, [plan_id=1207]\n            +- Filter isnotnull(product_id#820L)\n               +- Scan ExistingRDD[product_id#820L,category#821]\n\n\n+----------+------------+----------+\n|product_id|product_name|  category|\n+----------+------------+----------+\n|         1|   Product A|Category 1|\n|         2|   Product B|Category 2|\n+----------+------------+----------+\n\n"]}],"execution_count":10,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8b20190d-02b1-473c-baa6-53845c380a9f"},{"cell_type":"markdown","source":["### Performance Comparison:"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"836c15fb-74d6-4234-9c06-241991f36740"},{"cell_type":"code","source":["import time\n","\n","# Large dataset simulation\n","large_data = [(i, f\"Product_{i}\") for i in range(100000)]\n","small_data = [(i, f\"Category_{i%5}\") for i in range(100)]\n","\n","large_df = spark.createDataFrame(large_data, [\"id\", \"product\"])\n","small_df = spark.createDataFrame(small_data, [\"id\", \"category\"])\n","\n","# Regular join\n","start_time = time.time()\n","regular_join = large_df.join(small_df, \"id\")\n","regular_join.count()\n","regular_time = time.time() - start_time\n","\n","# Broadcast join\n","start_time = time.time()\n","broadcast_join = large_df.join(broadcast(small_df), \"id\")\n","broadcast_join.count()\n","broadcast_time = time.time() - start_time\n","\n","print(f\"Regular Join Time: {regular_time:.2f} seconds\")\n","print(f\"Broadcast Join Time: {broadcast_time:.2f} seconds\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":13,"statement_ids":[13],"state":"finished","livy_statement_state":"available","session_id":"fee2b172-d722-4d24-b54c-74a2e3116f71","normalized_state":"finished","queued_time":"2025-02-27T12:59:22.8230213Z","session_start_time":null,"execution_start_time":"2025-02-27T12:59:24.7785396Z","execution_finish_time":"2025-02-27T12:59:28.533728Z","parent_msg_id":"590ee83e-e91d-4ed0-9668-2f5eeddac891"},"text/plain":"StatementMeta(, fee2b172-d722-4d24-b54c-74a2e3116f71, 13, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Regular Join Time: 1.04 seconds\nBroadcast Join Time: 0.57 seconds\n"]}],"execution_count":11,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"faed81ad-5597-445d-a592-d975696527b2"},{"cell_type":"code","source":["# Key broadcast configurations\n","spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", 10485760)  # Set threshold to 10MB\n","spark.conf.set(\"spark.sql.shuffle.partitions\", 200)  # Default shuffle partitions"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":14,"statement_ids":[14],"state":"finished","livy_statement_state":"available","session_id":"fee2b172-d722-4d24-b54c-74a2e3116f71","normalized_state":"finished","queued_time":"2025-02-27T12:59:22.9650294Z","session_start_time":null,"execution_start_time":"2025-02-27T12:59:28.7069985Z","execution_finish_time":"2025-02-27T12:59:29.0015983Z","parent_msg_id":"c90168bf-75ba-48f3-b188-df306be73ac6"},"text/plain":"StatementMeta(, fee2b172-d722-4d24-b54c-74a2e3116f71, 14, Finished, Available, Finished)"},"metadata":{}}],"execution_count":12,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"67ac959d-541d-4c76-a938-296d88f5a6a9"},{"cell_type":"markdown","source":["## PySpark Broadcast Join Best Practices\n","\n","### Size Consideration\n","- **Optimal Size**: Broadcast smaller DataFrame (< 10MB by default)\n","- **Data Distribution**: Ensure even distribution across nodes"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"14e0ac49-a8d9-42fb-af48-949f568d9851"},{"cell_type":"code","source":["# Example of size checking before broadcast\n","def should_broadcast(df):\n","    # Get size estimate in bytes\n","    size_bytes = df._jdf.queryExecution().optimizedPlan().stats().sizeInBytes()\n","    size_mb = size_bytes / (1024 * 1024)\n","    return size_mb < 10  # Default threshold is 10MB\n","\n","small_df = spark.createDataFrame([(1, \"A\"), (2, \"B\")], [\"id\", \"value\"])\n","if should_broadcast(small_df):\n","    result = large_df.join(broadcast(small_df), \"id\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":15,"statement_ids":[15],"state":"finished","livy_statement_state":"available","session_id":"fee2b172-d722-4d24-b54c-74a2e3116f71","normalized_state":"finished","queued_time":"2025-02-27T12:59:23.0703343Z","session_start_time":null,"execution_start_time":"2025-02-27T12:59:29.1834395Z","execution_finish_time":"2025-02-27T12:59:29.4675717Z","parent_msg_id":"abe01e38-0957-4e45-abff-cac78bb7716c"},"text/plain":"StatementMeta(, fee2b172-d722-4d24-b54c-74a2e3116f71, 15, Finished, Available, Finished)"},"metadata":{}}],"execution_count":13,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"68ce4573-a0fd-4015-a82d-ddb36f7b4dd7"},{"cell_type":"markdown","source":["### Configuration Options:"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a6c5392d-8ffd-40ca-8f70-8b7682474387"},{"cell_type":"code","source":["# Key broadcast configurations\n","spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", 10485760)  # Set threshold to 10MB\n","spark.conf.set(\"spark.sql.shuffle.partitions\", 200)  # Default shuffle partitions"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":16,"statement_ids":[16],"state":"finished","livy_statement_state":"available","session_id":"fee2b172-d722-4d24-b54c-74a2e3116f71","normalized_state":"finished","queued_time":"2025-02-27T12:59:23.3096697Z","session_start_time":null,"execution_start_time":"2025-02-27T12:59:29.6410965Z","execution_finish_time":"2025-02-27T12:59:29.8873569Z","parent_msg_id":"c1bf3516-a16c-4347-bcf3-5e10a7687958"},"text/plain":"StatementMeta(, fee2b172-d722-4d24-b54c-74a2e3116f71, 16, Finished, Available, Finished)"},"metadata":{}}],"execution_count":14,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1fd0288c-c043-4f8f-8e96-5dbbef43c8b9"},{"cell_type":"markdown","source":["### Effectiveness\n","- **Smaller DataFrame**: Broadcast joins are most effective when one DataFrame is significantly smaller than the other.\n","- **Avoid Expensive Shuffling**: Use broadcast joins to avoid expensive shuffling operations.\n","- **Sufficient Memory**: Ensure you have enough memory on executor nodes to hold the broadcast DataFrame."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"60522819-f65c-439c-9ba8-662ccd9c5938"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}
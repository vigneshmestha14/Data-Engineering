{"cells":[{"cell_type":"markdown","source":["\n","# Casting and printSchema in PySpark\n","\n","In PySpark, we often need to change the data types of columns in a DataFrame using the `cast()` function.\n","The `printSchema()` function is used to display the structure of a DataFrame, including column names and data types."],"metadata":{},"id":"7d793394"},{"cell_type":"code","source":["\n","from pyspark.sql import SparkSession\n","from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n","\n","# Create a Spark session\n","spark = SparkSession.builder.appName(\"CastingExample\").getOrCreate()\n","\n","# Define schema\n","schema = StructType([\n","    StructField(\"name\", StringType(), True),\n","    StructField(\"age\", StringType(), True),\n","    StructField(\"salary\", StringType(), True)\n","])\n","\n","# Sample data\n","data = [(\"Alice\", \"30\", \"50000\"), (\"Bob\", \"40\", \"60000\"), (\"Charlie\", \"35\", \"70000\")]\n","\n","# Create DataFrame\n","df = spark.createDataFrame(data, schema)\n","\n","# Print schema before casting\n","df.printSchema()\n","\n","# Show data\n","df.show()\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"abdd20bc-8567-4154-8559-bbbb1ce7c652","normalized_state":"finished","queued_time":"2025-03-03T15:43:19.2128173Z","session_start_time":"2025-03-03T15:43:19.2142003Z","execution_start_time":"2025-03-03T15:43:28.6097525Z","execution_finish_time":"2025-03-03T15:43:32.1287524Z","parent_msg_id":"91bc7ed5-c59f-460a-80f8-0b2bf41958e3"},"text/plain":"StatementMeta(, abdd20bc-8567-4154-8559-bbbb1ce7c652, 3, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["root\n |-- name: string (nullable = true)\n |-- age: string (nullable = true)\n |-- salary: string (nullable = true)\n\n+-------+---+------+\n|   name|age|salary|\n+-------+---+------+\n|  Alice| 30| 50000|\n|    Bob| 40| 60000|\n|Charlie| 35| 70000|\n+-------+---+------+\n\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"72a0b8c8"},{"cell_type":"markdown","source":["\n","## 2. Casting Data Types\n","\n","We will now cast the `age` and `salary` columns from `StringType` to `IntegerType`.\n"],"metadata":{},"id":"227b46c8"},{"cell_type":"code","source":["\n","from pyspark.sql.functions import col\n","\n","# Cast columns to IntegerType\n","df_casted = df.withColumn(\"age\", col(\"age\").cast(IntegerType()))\\\n","               .withColumn(\"salary\", col(\"salary\").cast(IntegerType()))\n","\n","# Print schema after casting\n","df_casted.printSchema()\n","\n","# Show transformed data\n","df_casted.show()\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"abdd20bc-8567-4154-8559-bbbb1ce7c652","normalized_state":"finished","queued_time":"2025-03-03T15:43:19.2346391Z","session_start_time":null,"execution_start_time":"2025-03-03T15:43:32.327674Z","execution_finish_time":"2025-03-03T15:43:33.1858488Z","parent_msg_id":"e691e281-c012-42ae-a4a3-d271193e2972"},"text/plain":"StatementMeta(, abdd20bc-8567-4154-8559-bbbb1ce7c652, 4, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["root\n |-- name: string (nullable = true)\n |-- age: integer (nullable = true)\n |-- salary: integer (nullable = true)\n\n+-------+---+------+\n|   name|age|salary|\n+-------+---+------+\n|  Alice| 30| 50000|\n|    Bob| 40| 60000|\n|Charlie| 35| 70000|\n+-------+---+------+\n\n"]}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"60a36e08"},{"cell_type":"markdown","source":["\n","## 3. Conclusion\n","\n","- The `printSchema()` function allows us to check the structure of a DataFrame.\n","- The `cast()` function is used to change column data types.\n","- Casting is useful when reading data where numerical values are stored as strings.\n","\n","This demonstrates how to properly convert data types in PySpark!\n"],"metadata":{},"id":"dfc3f9cc"}],"metadata":{"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"kernel_info":{"name":"synapse_pyspark"},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}}},"nbformat":4,"nbformat_minor":5}
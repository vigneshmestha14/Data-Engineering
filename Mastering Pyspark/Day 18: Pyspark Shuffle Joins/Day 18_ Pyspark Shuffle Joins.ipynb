{"cells":[{"cell_type":"markdown","source":["## PySpark Shuffle Join Explanation\n","\n","### What is a Shuffle Join?\n","A shuffle join in PySpark occurs when data needs to be redistributed across partitions before performing the join operation. This happens when the join key's data is not co-located on the same partition.\n","\n","### Implementation Examples\n","#### Basic Shuffle Join"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"0c2e08cc-fb8c-4e2e-a3dd-8fbe3f485f58"},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col\n","\n","# Initialize Spark Session\n","spark = SparkSession.builder \\\n","    .appName(\"Shuffle Join Example\") \\\n","    .getOrCreate()\n","\n","# Create sample DataFrames\n","df1 = spark.createDataFrame([\n","    (1, \"A\", 1000),\n","    (2, \"B\", 2000),\n","    (3, \"C\", 3000)\n","], [\"id\", \"name\", \"salary\"])\n","\n","df2 = spark.createDataFrame([\n","    (1, \"HR\"),\n","    (2, \"IT\"),\n","    (4, \"Finance\")\n","], [\"id\", \"department\"])\n","\n","# Perform shuffle join\n","shuffle_join = df1.join(df2, \"id\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":11,"statement_ids":[11],"state":"finished","livy_statement_state":"available","session_id":"598cd32b-276f-43f7-990a-e178bb63cb39","normalized_state":"finished","queued_time":"2025-02-28T12:51:04.6720879Z","session_start_time":null,"execution_start_time":"2025-02-28T12:51:04.8667698Z","execution_finish_time":"2025-02-28T12:51:05.1290599Z","parent_msg_id":"a5a7e581-43e9-40df-bfc8-513e9ca5ea9b"},"text/plain":"StatementMeta(, 598cd32b-276f-43f7-990a-e178bb63cb39, 11, Finished, Available, Finished)"},"metadata":{}}],"execution_count":9,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"040f41a7-de6a-4fe4-b6be-8b657aaf3ec8"},{"cell_type":"markdown","source":["### Optimizing Shuffle Joins\n","1. Using Partitioning"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5ad33ef6-c6b1-4cd2-b7fa-5280f11cc4e9"},{"cell_type":"code","source":["# Repartition DataFrames before joining\n","df1_partitioned = df1.repartition(col(\"id\"))\n","df2_partitioned = df2.repartition(col(\"id\"))\n","\n","optimized_join = df1_partitioned.join(df2_partitioned, \"id\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":12,"statement_ids":[12],"state":"finished","livy_statement_state":"available","session_id":"598cd32b-276f-43f7-990a-e178bb63cb39","normalized_state":"finished","queued_time":"2025-02-28T12:51:04.7314602Z","session_start_time":null,"execution_start_time":"2025-02-28T12:51:05.3264047Z","execution_finish_time":"2025-02-28T12:51:05.647641Z","parent_msg_id":"26675adf-ffa1-49fc-be1d-c4d7eb99c339"},"text/plain":"StatementMeta(, 598cd32b-276f-43f7-990a-e178bb63cb39, 12, Finished, Available, Finished)"},"metadata":{}}],"execution_count":10,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3589b348-2734-45e8-bfd1-df1d1ae781c1"},{"cell_type":"markdown","source":["### 2. Controlling Shuffle Partitions"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f24295f8-d662-4ca2-963d-e46a76bb2b2e"},{"cell_type":"code","source":["# Set number of shuffle partitions\n","spark.conf.set(\"spark.sql.shuffle.partitions\", 10)\n","\n","# Monitor partition size\n","def show_partition_counts(df, name):\n","    print(f\"{name} partition count: {df.rdd.getNumPartitions()}\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":13,"statement_ids":[13],"state":"finished","livy_statement_state":"available","session_id":"598cd32b-276f-43f7-990a-e178bb63cb39","normalized_state":"finished","queued_time":"2025-02-28T12:51:04.7982311Z","session_start_time":null,"execution_start_time":"2025-02-28T12:51:05.8242619Z","execution_finish_time":"2025-02-28T12:51:06.1331005Z","parent_msg_id":"ac541237-9ae6-421d-9e1a-5b0581f46b82"},"text/plain":"StatementMeta(, 598cd32b-276f-43f7-990a-e178bb63cb39, 13, Finished, Available, Finished)"},"metadata":{}}],"execution_count":11,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"698df162-48ae-49c5-9942-e54fbb79b35f"},{"cell_type":"markdown","source":["### Performance Monitoring"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fe217837-a547-4775-aeab-6e5d1593120b"},{"cell_type":"code","source":["def analyze_join_performance(df1, df2, join_key):\n","    \"\"\"Analyze join performance with different configurations\"\"\"\n","    \n","    # Original join\n","    start_time = time.time()\n","    regular_join = df1.join(df2, join_key)\n","    regular_time = time.time() - start_time\n","    \n","    # Optimized join with repartitioning\n","    start_time = time.time()\n","    optimized_join = df1.repartition(join_key).join(\n","        df2.repartition(join_key),\n","        join_key\n","    )\n","    optimized_time = time.time() - start_time\n","    \n","    print(f\"Regular Join Time: {regular_time:.2f} seconds\")\n","    print(f\"Optimized Join Time: {optimized_time:.2f} seconds\")\n","    print(\"\\nExecution Plans:\")\n","    print(\"Regular Join:\")\n","    regular_join.explain()\n","    print(\"\\nOptimized Join:\")\n","    optimized_join.explain()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":14,"statement_ids":[14],"state":"finished","livy_statement_state":"available","session_id":"598cd32b-276f-43f7-990a-e178bb63cb39","normalized_state":"finished","queued_time":"2025-02-28T12:51:04.8841677Z","session_start_time":null,"execution_start_time":"2025-02-28T12:51:06.3273168Z","execution_finish_time":"2025-02-28T12:51:06.5873915Z","parent_msg_id":"c4b7531b-bcbf-4e8f-b211-4b78e6a2e6e7"},"text/plain":"StatementMeta(, 598cd32b-276f-43f7-990a-e178bb63cb39, 14, Finished, Available, Finished)"},"metadata":{}}],"execution_count":12,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3e40ddd1-08c0-493d-91db-edcbe2b6effb"},{"cell_type":"markdown","source":["### Best Practices\n","1. Partition Size Management\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"286105ab-7d7a-46c8-9c33-8397e1c83627"},{"cell_type":"code","source":["def optimize_partition_size(df, target_size_mb=128):\n","    \"\"\"Optimize number of partitions based on data size\"\"\"\n","    total_bytes = df._jdf.queryExecution().optimizedPlan().stats().sizeInBytes()\n","    total_mb = total_bytes / (1024 * 1024)\n","    optimal_partitions = max(1, int(total_mb / target_size_mb))\n","    return df.repartition(optimal_partitions)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":15,"statement_ids":[15],"state":"finished","livy_statement_state":"available","session_id":"598cd32b-276f-43f7-990a-e178bb63cb39","normalized_state":"finished","queued_time":"2025-02-28T12:51:04.9285919Z","session_start_time":null,"execution_start_time":"2025-02-28T12:51:06.770225Z","execution_finish_time":"2025-02-28T12:51:07.0438361Z","parent_msg_id":"694fe6bb-1f12-4490-8922-179a58dfa953"},"text/plain":"StatementMeta(, 598cd32b-276f-43f7-990a-e178bb63cb39, 15, Finished, Available, Finished)"},"metadata":{}}],"execution_count":13,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a9b2aee5-6bd4-4847-a83a-b7f70ad28f46"},{"cell_type":"markdown","source":["### 2. Join Strategy Selection"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0c72fc5d-cd95-4d86-ba27-8594c9d553ec"},{"cell_type":"code","source":["def select_join_strategy(df1, df2, join_key):\n","    \"\"\"Select appropriate join strategy based on DataFrame sizes\"\"\"\n","    df1_size = df1._jdf.queryExecution().optimizedPlan().stats().sizeInBytes()\n","    df2_size = df2._jdf.queryExecution().optimizedPlan().stats().sizeInBytes()\n","    \n","    broadcast_threshold = 10 * 1024 * 1024  # 10MB\n","    \n","    if min(df1_size, df2_size) < broadcast_threshold:\n","        # Use broadcast join for small DataFrames\n","        return df1.join(broadcast(df2), join_key)\n","    else:\n","        # Use shuffle join with optimized partitioning\n","        return df1.repartition(join_key).join(\n","            df2.repartition(join_key),\n","            join_key\n","        )"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":16,"statement_ids":[16],"state":"finished","livy_statement_state":"available","session_id":"598cd32b-276f-43f7-990a-e178bb63cb39","normalized_state":"finished","queued_time":"2025-02-28T12:51:05.1267103Z","session_start_time":null,"execution_start_time":"2025-02-28T12:51:07.2070971Z","execution_finish_time":"2025-02-28T12:51:07.4735016Z","parent_msg_id":"72e46e18-b838-40e5-88cc-b3e2a7d9ecf1"},"text/plain":"StatementMeta(, 598cd32b-276f-43f7-990a-e178bb63cb39, 16, Finished, Available, Finished)"},"metadata":{}}],"execution_count":14,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"390efa6a-b56d-4510-ace4-75c844196448"},{"cell_type":"markdown","source":["### Monitoring and Debugging"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"34a22909-ef65-4d06-b005-e13c0dab33a5"},{"cell_type":"code","source":["def monitor_shuffle_metrics(df):\n","    \"\"\"Monitor shuffle metrics for a DataFrame operation\"\"\"\n","    df.persist()  # Cache the DataFrame\n","    \n","    # Trigger computation and get metrics\n","    df.count()\n","    \n","    # Get Spark context\n","    sc = SparkSession.builder.getOrCreate().sparkContext\n","    \n","    # Print metrics\n","    print(\"Shuffle Metrics:\")\n","    print(f\"Shuffle Read: {sc.statusTracker().getExecutorMetrics()}\")\n","    \n","    df.unpersist()  # Clean up"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":17,"statement_ids":[17],"state":"finished","livy_statement_state":"available","session_id":"598cd32b-276f-43f7-990a-e178bb63cb39","normalized_state":"finished","queued_time":"2025-02-28T12:51:05.2241845Z","session_start_time":null,"execution_start_time":"2025-02-28T12:51:07.6485581Z","execution_finish_time":"2025-02-28T12:51:07.8997076Z","parent_msg_id":"4db67c53-c5bc-4862-bb21-856d76cffe01"},"text/plain":"StatementMeta(, 598cd32b-276f-43f7-990a-e178bb63cb39, 17, Finished, Available, Finished)"},"metadata":{}}],"execution_count":15,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4a88c0d1-b971-445d-86df-ecbf061b95af"},{"cell_type":"markdown","source":["### Remember:\n","\n","1. Monitor shuffle spill metrics\n","2. Use appropriate number of partitions\n","3. Consider data skew\n","4. Test with representative data volumes"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"893e35c1-76c5-4afb-b7e9-e2fda8ebc34d"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}